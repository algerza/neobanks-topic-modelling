{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Topic Modeling?\n",
    "Topic modeling can be easily compared to clustering. By doing topic modeling we build clusters of words rather than clusters of texts. A text is thus a mixture of all the topics, each having a certain weight.\n",
    "\n",
    "### How it works?\n",
    "If document classification is assigning a single category to a text, topic modeling is assigning multiple tags to a text. A human expert can label the resulting topics with human-readable labels and use different heuristics to convert the weighted topics to a set of tags.\n",
    "\n",
    "### Why do you need it?\n",
    "There are several scenarios when topic modeling can prove useful. Here are some of them:\n",
    "\n",
    "- Text classification – Topic modeling can improve classification by grouping similar words together in topics rather than using each word as a feature\n",
    "- Recommender Systems – Using a similarity measure we can build recommender systems. If our system would recommend articles for readers, it will recommend articles with a topic structure similar to the articles the user has already read.\n",
    "- Uncovering Themes in Texts – Useful for detecting trends in online publications for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAzurFW2dZzr"
   },
   "source": [
    "# 1. Install and load the necessary packages\n",
    "All the packages needed from crawling to sentiment analysis can be found on this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "cVg1TPdxX_rN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.json import json_normalize\n",
    "from google_play_scraper import app,Sort, reviews\n",
    "from app_store_scraper import AppStore\n",
    "from pprint import pprint\n",
    "import urllib3\n",
    "import xmltodict\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import spacy \n",
    "import langid \n",
    "from nltk.classify.textcat import TextCat \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data\n",
    "This step can be skipped if you're scraping directly the data on the same script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our previously scraped data\n",
    "play_store_reviews = pd.read_csv('play_store_reviews.csv', index_col=False)\n",
    "app_store_reviews = pd.read_csv('app_store_reviews.csv', index_col=False)\n",
    "\n",
    "# Add paltform names to each review\n",
    "app_store_reviews = app_store_reviews.assign(Platform='iOS')\n",
    "play_store_reviews = play_store_reviews.assign(Platform='Android')\n",
    "\n",
    "# Select the relevant columns\n",
    "app_store_reviews = app_store_reviews[['App', 'Rating', 'Comment', 'Platform']]\n",
    "play_store_reviews = play_store_reviews[['App', 'Rating', 'Comment', 'Platform']]\n",
    "\n",
    "# Create final dataset combining reviews from App \n",
    "app_store_reviews['App'] = app_store_reviews['App'].str.replace('revolut', 'Revolut')\n",
    "app_store_reviews['App'] = app_store_reviews['App'].str.replace('n26-mobile-banking', 'N26')\n",
    "app_store_reviews['App'] = app_store_reviews['App'].str.replace('monzo-bank', 'MonzoBank')\n",
    "df_reviews = play_store_reviews.append(app_store_reviews,ignore_index=True)\n",
    "\n",
    "# Keep only reviews with a meaningful lenght (15 characters)\n",
    "df_reviews = df_reviews[df_reviews.Comment.str.len()>=15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will classify our reviews based on the language they are written down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tagged languages (estimated):\n",
      "77\n",
      "Percent of data in English (estimated):\n",
      "90.4166594420266\n"
     ]
    }
   ],
   "source": [
    "# Get the language id for each review\n",
    "ids_langid = df_reviews['Comment'].apply(langid.classify)\n",
    "\n",
    "# Get just the language label\n",
    "langs = ids_langid.apply(lambda tuple: tuple[0])\n",
    "\n",
    "# Assign the language to each review\n",
    "df_reviews['Language'] = langs\n",
    "\n",
    "# How many unique language labels were applied?\n",
    "print(\"Number of tagged languages (estimated):\")\n",
    "print(len(langs.unique()))\n",
    "\n",
    "# Percent of the total dataset in English\n",
    "print(\"Percent of data in English (estimated):\")\n",
    "print((sum(langs==\"en\")/len(langs))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revolut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good and efficient</td>\n",
       "      <td>Android</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revolut</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The transfers take a lot longer to hit your in...</td>\n",
       "      <td>Android</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There is a lot of wasted space in the vaults.....</td>\n",
       "      <td>Android</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revolut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Everything you could possibly need from a bank...</td>\n",
       "      <td>Android</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revolut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Revolut is a brilliant app that saves you lots...</td>\n",
       "      <td>Android</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75941</th>\n",
       "      <td>bunq</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The bank is good but the new app became super ...</td>\n",
       "      <td>iOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75942</th>\n",
       "      <td>bunq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The new version has Terrible accessibility</td>\n",
       "      <td>iOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75943</th>\n",
       "      <td>bunq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This bank used to have one of the best user ex...</td>\n",
       "      <td>iOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75945</th>\n",
       "      <td>bunq</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fantastic bank for modern thinking people who ...</td>\n",
       "      <td>iOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75947</th>\n",
       "      <td>bunq</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why would you let US residents sign up to tell...</td>\n",
       "      <td>iOS</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           App  Rating                                            Comment  \\\n",
       "0      Revolut     5.0                                 Good and efficient   \n",
       "1      Revolut     3.0  The transfers take a lot longer to hit your in...   \n",
       "2      Revolut     5.0  There is a lot of wasted space in the vaults.....   \n",
       "3      Revolut     5.0  Everything you could possibly need from a bank...   \n",
       "4      Revolut     5.0  Revolut is a brilliant app that saves you lots...   \n",
       "...        ...     ...                                                ...   \n",
       "75941     bunq     3.0  The bank is good but the new app became super ...   \n",
       "75942     bunq     1.0         The new version has Terrible accessibility   \n",
       "75943     bunq     1.0  This bank used to have one of the best user ex...   \n",
       "75945     bunq     5.0  Fantastic bank for modern thinking people who ...   \n",
       "75947     bunq     1.0  Why would you let US residents sign up to tell...   \n",
       "\n",
       "      Platform Language  \n",
       "0      Android       en  \n",
       "1      Android       en  \n",
       "2      Android       en  \n",
       "3      Android       en  \n",
       "4      Android       en  \n",
       "...        ...      ...  \n",
       "75941      iOS       en  \n",
       "75942      iOS       en  \n",
       "75943      iOS       en  \n",
       "75945      iOS       en  \n",
       "75947      iOS       en  \n",
       "\n",
       "[52146 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% of the reviews are in English. The population seems to be well represented in that group\n",
    "#     We will select English reviews only\n",
    "\n",
    "df_reviews = df_reviews[df_reviews['Language']=='en']\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model\n",
    "Our goal is to classify bad reviews under meaningful topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of total reviews are rated below 4: 31.60740996433092\n"
     ]
    }
   ],
   "source": [
    "# What are people complaining about? Ratings below 4 and at least 15 characters\n",
    "reviews = df_reviews[df_reviews['Rating']<=3]\n",
    "reviews = reviews[['App','Comment']].drop_duplicates()\n",
    "reviews.dropna(inplace=True)\n",
    "reviews = reviews.reset_index().drop(columns='index')\n",
    "print(f'% of total reviews are rated below 4: {len(reviews)/len(df_reviews)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document term matrix of the reviews\n",
    "#   max_df : discard words that occur more than 95% documents\n",
    "#   min_df : include only those words that occur atleast in 2 documents\n",
    "    \n",
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "reviews_cv = cv.fit_transform(reviews['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=4, random_state=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA model with 4 topics\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=4,random_state=1)\n",
    "LDA.fit(reviews_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic #0 : \n",
      "['bunq', 'old', 'bank', 'banking', 'used', 'ui', 'features', 'user', 'great', 'revolut', 'don', 'good', 'just', 'version', 'really', 'like', 'use', 'new', 'update', 'app']\n",
      "topic #1 : \n",
      "['ve', 'help', 'reason', 'chat', 'contact', 'revolut', 'just', 'email', 'use', 'support', 'number', 'don', 'access', 'phone', 'customer', 'service', 'bank', 'app', 'money', 'account']\n",
      "topic #2 : \n",
      "['need', 'just', 'passport', 'n26', 'bank', 'identity', 'time', 'money', 'verification', 'card', 'revolut', 'verify', 'days', 'id', 'account', 'app', 'chat', 'service', 'customer', 'support']\n",
      "topic #3 : \n",
      "['phone', 'monzo', 'does', 'don', 'transfer', 'tried', 'try', 'free', 'just', 'money', 'use', 'revolut', 'doesn', 'time', 'pay', 'bank', 'work', 'account', 'app', 'card']\n"
     ]
    }
   ],
   "source": [
    "# Extract the topics and their most represented words\n",
    "\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'topic #{index} : ')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-20:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results into our initial dataset and save it\n",
    "topic_reviews = LDA.transform(reviews_cv)\n",
    "\n",
    "df_topic_reviews = pd.DataFrame(topic_reviews, columns=[\n",
    "'0_app_functionality',\n",
    "'1_customer_support/account_blocking' ,\n",
    "'2_validation/verification'            ,\n",
    "'3_financial_products'\n",
    "])\n",
    "\n",
    "df_result_low = pd.merge(reviews, df_topic_reviews,  how='inner', left_index=True, right_index=True)\n",
    "df_result_low\n",
    "\n",
    "df_result_low.to_csv(\"df_result_low.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation\n",
    "Let's create a random sample of 10 reviews for each app and manually check if the labels assigned are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random sample dataset and save it\n",
    "rev = df_result_low[df_result_low['App']=='Revolut'].sample(n=10, random_state=1)\n",
    "rev\n",
    "\n",
    "n26 = df_result_low[df_result_low['App']=='N26'].sample(n=10, random_state=1)\n",
    "n26\n",
    "\n",
    "MonzoBank = df_result_low[df_result_low['App']=='MonzoBank'].sample(n=10, random_state=1)\n",
    "MonzoBank\n",
    "\n",
    "bunq = df_result_low[df_result_low['App']=='bunq'].sample(n=10, random_state=1)\n",
    "bunq\n",
    "\n",
    "sample = rev.append(n26).append(MonzoBank).append(bunq)\n",
    "sample.to_excel(\"sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy (number of correctly labeled reviews / total reviews) is: 72.5%\n"
     ]
    }
   ],
   "source": [
    "# Manually labeled 40 reviews (5 reviews per app) and determined if the categorisation was correct\n",
    "validation = pd.read_csv('validation.csv')\n",
    "validation = validation.reset_index().drop(columns='index')\n",
    "accuracy = validation['IsAccurate'].sum() / validation['IsAccurate'].count()\n",
    "\n",
    "print(f'The model accuracy (number of correctly labeled reviews / total reviews) is: {accuracy *100}'+\"%\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "y5dWUxZxa2QK",
    "UWUvhRQfa6_G",
    "zCWRJlKqTnsJ"
   ],
   "name": "222222 of Sound Enhancers Comparison.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
